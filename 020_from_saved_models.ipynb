{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Models testing",
   "id": "cee9eab6c7fbbee8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import os\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import explained_variance_score, mean_absolute_error, mean_squared_error, r2_score, make_scorer, mean_absolute_percentage_error, median_absolute_error, PredictionErrorDisplay\n",
    "\n",
    "testing = pd.read_csv(\"data/testing_df.csv\")\n",
    "testing.drop(columns=testing.columns[0], axis=1,  inplace=True)\n",
    "testing = testing.loc[testing[\"price\"]< 1000, :]\n",
    "train_set, test_set = train_test_split(testing, test_size=0.2, random_state=874631)\n",
    "X_train = train_set.drop([\"price\"], axis=1)\n",
    "X_test = test_set.drop([\"price\"], axis=1)\n",
    "y_train = train_set[\"price\"]\n",
    "y_test = test_set[\"price\"]\n",
    "\n"
   ],
   "id": "243304745e288805",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "testing.shape",
   "id": "b134fae6f9f73257",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "testing.head()",
   "id": "c004cce101ffdf91",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Multi Layer Perceptron Regression\n"
   ],
   "id": "269d84ff70b322bb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "best_pipe = joblib.load(\"pickle/MLPR_less1k.pkl\")\n",
    "pred = best_pipe.predict(X_test)\n",
    "print(\n",
    "    f\"\\nExplained variance score is {explained_variance_score(y_true=y_test, y_pred=pred)}\",\n",
    "    f\"\\nMean Absolute Error is {mean_absolute_error(y_true=y_test, y_pred=pred)}\",\n",
    "    f\"\\nMean Absolute Percentage error is {round(100 * mean_absolute_percentage_error(y_true=y_test, y_pred=pred), 2)}%\",\n",
    "    f\"\\nMedian Absolute Error is {median_absolute_error(y_true=y_test, y_pred=pred)}\",\n",
    "    f\"\\nMean Squared Error is {mean_squared_error(y_true=y_test, y_pred=pred)}\",\n",
    "    f\"\\nR^2 Error is {r2_score(y_true=y_test, y_pred=pred)}\",\n",
    ")\n",
    "results = pd.DataFrame(data={\"Pred\": pred, \"y_test\": y_test})\n",
    "results[\"Difference\"] = abs(results[\"Pred\"] - results[\"y_test\"])\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(best_pipe[\"Model\"].loss_curve_, label='Loss Curve', color='blue')\n",
    "plt.title('Loss Curve During Training')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, pred, color='orange', label='Predictions')\n",
    "plt.plot([y_test.min(), y_test.max()], [pred.min(), pred.max()], 'k--', lw=2, label='Perfect Prediction')\n",
    "plt.title('True vs Predicted Values')\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "display = PredictionErrorDisplay(y_true=y_test, y_pred=pred)\n",
    "display.plot()\n",
    "plt.show()\n"
   ],
   "id": "5ddecf756918ae14",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Random Forest Regression",
   "id": "d83ba0d2a8b1fb40"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "best_pipe = joblib.load(\"pickle/RFR.pkl\")\n",
    "pred = best_pipe.predict(X_test)\n",
    "print(\n",
    "    f\"\\nExplained variance score is {explained_variance_score(y_true=y_test, y_pred=pred)}\",\n",
    "    f\"\\nMean Absolute Error is {mean_absolute_error(y_true=y_test, y_pred=pred)}\",\n",
    "    f\"\\nMean Absolute Percentage error is {round(100 * mean_absolute_percentage_error(y_true=y_test, y_pred=pred), 2)}%\",\n",
    "    f\"\\nMedian Absolute Error is {median_absolute_error(y_true=y_test, y_pred=pred)}\",\n",
    "    f\"\\nMean Squared Error is {mean_squared_error(y_true=y_test, y_pred=pred)}\",\n",
    "    f\"\\nR^2 Error is {r2_score(y_true=y_test, y_pred=pred)}\",\n",
    ")\n",
    "results = pd.DataFrame(data={\"Pred\": pred, \"y_test\": y_test})\n",
    "results[\"Difference\"] = abs(results[\"Pred\"] - results[\"y_test\"])\n",
    "sum(results[\"Difference\"] > 100) / results.shape[0]\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, pred, color='orange', label='Predictions')\n",
    "plt.plot([y_test.min(), y_test.max()], [pred.min(), pred.max()], 'k--', lw=2, label='Perfect Prediction')\n",
    "plt.title('True vs Predicted Values')\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "display = PredictionErrorDisplay(y_true=y_test, y_pred=pred)\n",
    "display.plot()\n",
    "plt.show()\n",
    "\n"
   ],
   "id": "a86015425f4f9f1a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Linear Support Vector Regression",
   "id": "182829b3ec2e94a8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "best_pipe = joblib.load(\"pickle/LinearSVR.pkl\")\n",
    "pred = best_pipe.predict(X_test)\n",
    "print(\n",
    "    f\"\\nExplained variance score is {explained_variance_score(y_true=y_test, y_pred=pred)}\",\n",
    "    f\"\\nMean Absolute Error is {mean_absolute_error(y_true=y_test, y_pred=pred)}\",\n",
    "    f\"\\nMean Absolute Percentage error is {round(100 * mean_absolute_percentage_error(y_true=y_test, y_pred=pred), 2)}%\",\n",
    "    f\"\\nMedian Absolute Error is {median_absolute_error(y_true=y_test, y_pred=pred)}\",\n",
    "    f\"\\nMean Squared Error is {mean_squared_error(y_true=y_test, y_pred=pred)}\",\n",
    "    f\"\\nR^2 Error is {r2_score(y_true=y_test, y_pred=pred)}\",\n",
    ")\n",
    "results = pd.DataFrame(data={\"Pred\": pred, \"y_test\": y_test})\n",
    "results[\"Difference\"] = abs(results[\"Pred\"] - results[\"y_test\"])\n",
    "sum(results[\"Difference\"] > 100) / results.shape[0]\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, pred, color='orange', label='Predictions')\n",
    "plt.plot([y_test.min(), y_test.max()], [pred.min(), pred.max()], 'k--', lw=2, label='Perfect Prediction')\n",
    "plt.title('True vs Predicted Values')\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "plt.savefig('images/LinearSVR_true_vs_pred.png', format='png')\n",
    "\n",
    "display = PredictionErrorDisplay(y_true=y_test, y_pred=pred)\n",
    "display.plot()\n",
    "plt.show()\n",
    "plt.savefig('images/LinearSVR_residuals.png', format='png')\n",
    "\n"
   ],
   "id": "6bac4cb36568a337",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Nu Support Vector Regression",
   "id": "bfe616426ee54cd6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "best_pipe = joblib.load(\"pickle/NuSVR.pkl\")\n",
    "pred = best_pipe.predict(X_test)\n",
    "print(\n",
    "    f\"\\nExplained variance score is {explained_variance_score(y_true=y_test, y_pred=pred)}\",\n",
    "    f\"\\nMean Absolute Error is {mean_absolute_error(y_true=y_test, y_pred=pred)}\",\n",
    "    f\"\\nMean Absolute Percentage error is {round(100 * mean_absolute_percentage_error(y_true=y_test, y_pred=pred), 2)}%\",\n",
    "    f\"\\nMedian Absolute Error is {median_absolute_error(y_true=y_test, y_pred=pred)}\",\n",
    "    f\"\\nMean Squared Error is {mean_squared_error(y_true=y_test, y_pred=pred)}\",\n",
    "    f\"\\nR^2 Error is {r2_score(y_true=y_test, y_pred=pred)}\",\n",
    ")\n",
    "results = pd.DataFrame(data={\"Pred\": pred, \"y_test\": y_test})\n",
    "results[\"Difference\"] = abs(results[\"Pred\"] - results[\"y_test\"])\n",
    "sum(results[\"Difference\"] > 100) / results.shape[0]\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, pred, color='orange', label='Predictions')\n",
    "plt.plot([y_test.min(), y_test.max()], [pred.min(), pred.max()], 'k--', lw=2, label='Perfect Prediction')\n",
    "plt.title('True vs Predicted Values')\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "display = PredictionErrorDisplay(y_true=y_test, y_pred=pred)\n",
    "display.plot()\n",
    "plt.show()\n",
    "\n"
   ],
   "id": "5ba8927ae58ee5e1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## KNN Regression",
   "id": "4a23a3f4eb09039c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "best_pipe = joblib.load(\"pickle/KNNR.pkl\")\n",
    "pred = best_pipe.predict(X_test)\n",
    "print(\n",
    "    f\"\\nExplained variance score is {explained_variance_score(y_true=y_test, y_pred=pred)}\",\n",
    "    f\"\\nMean Absolute Error is {mean_absolute_error(y_true=y_test, y_pred=pred)}\",\n",
    "    f\"\\nMean Absolute Percentage error is {round(100 * mean_absolute_percentage_error(y_true=y_test, y_pred=pred), 2)}%\",\n",
    "    f\"\\nMedian Absolute Error is {median_absolute_error(y_true=y_test, y_pred=pred)}\",\n",
    "    f\"\\nMean Squared Error is {mean_squared_error(y_true=y_test, y_pred=pred)}\",\n",
    "    f\"\\nR^2 Error is {r2_score(y_true=y_test, y_pred=pred)}\",\n",
    ")\n",
    "results = pd.DataFrame(data={\"Pred\": pred, \"y_test\": y_test})\n",
    "results[\"Difference\"] = abs(results[\"Pred\"] - results[\"y_test\"])\n",
    "sum(results[\"Difference\"] > 100) / results.shape[0]\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, pred, color='orange', label='Predictions')\n",
    "plt.plot([y_test.min(), y_test.max()], [pred.min(), pred.max()], 'k--', lw=2, label='Perfect Prediction')\n",
    "plt.title('True vs Predicted Values')\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "display = PredictionErrorDisplay(y_true=y_test, y_pred=pred)\n",
    "display.plot()\n",
    "plt.show()\n"
   ],
   "id": "6b0c46276f34d067",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
